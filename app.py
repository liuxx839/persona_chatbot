import streamlit as st
from zhipuai import ZhipuAI
from openai import OpenAI
import random
import time
from datetime import datetime
from persona import PERSONAS # Import personas
from groq import Groq
import compressed_memory as cm
import detailed_memory as dm
import os

# --- é…ç½® ---
MAX_HISTORY_LEN = 20 # LLM å¯è§çš„æœ€å¤§æ¶ˆæ¯æ•°
MAX_BOT_MEMORY_LEN = 20 # æ¯ä¸ªæœºå™¨äººå·¥ä½œè®°å¿†çš„æœ€å¤§æ¡ç›®æ•°
SUMMARY_INTERVAL = 3 # æ¯éš”å¤šå°‘è½®æ€»æ¶ˆæ¯è¿›è¡Œä¸€æ¬¡æ€»ç»“
BOT_RESPONSE_DELAY = (0, 0) # æœºå™¨äººå“åº”å»¶è¿Ÿç§’æ•°èŒƒå›´ï¼ˆæœ€å°å€¼ï¼Œæœ€å¤§å€¼ï¼‰
MEMORY_COMPRESSION_INTERVAL = 3 # æ¯éš”å¤šå°‘æ¬¡è®°å¿†æ›´æ–°å‹ç¼©ä¸€æ¬¡è®°å¿†

# --- Groq API è®¾ç½® ---
try:
    # client = ZhipuAI(api_key='')
    # LLM_MODEL = "glm-4-flash" # Zhipu AI model
    # client = Groq(api_key='')
    # LLM_MODEL = "llama3-70b-8192" # Groq æ¨¡å‹
    api_key = os.environ.get("GEMINI_API_KEY")
    client = OpenAI(api_key=api_key,base_url="https://generativelanguage.googleapis.com/v1beta/")
    LLM_MODEL = "gemini-2.0-flash" # Groq æ¨¡å‹

except KeyError:
    st.error("API å¯†é’¥æœªæ‰¾åˆ°ã€‚è¯·åœ¨ .streamlit/secrets.toml ä¸­è®¾ç½®å®ƒ")
    st.stop()


# --- è¾…åŠ©å‡½æ•° ---

def get_llm_response(persona_name, persona_details, chat_history, bot_memory, compressed_memory_text=""):
    """
    æ ¹æ®è§’è‰²ã€å†å²è®°å½•å’Œè®°å¿†è·å– LLM çš„å“åº”ã€‚
    å¢åŠ äº†å‹ç¼©è®°å¿†å‚æ•°ï¼Œä¸ºè§’è‰²æä¾›é•¿æœŸç»éªŒã€‚
    """
    system_prompt = (
        f"ä½ æ˜¯ {persona_name}ã€‚{persona_details['description']}\n"
        f"ä½ çš„èƒŒæ™¯ï¼š{persona_details['background']}\n"
    )
    
    # æ·»åŠ å‹ç¼©è®°å¿†ï¼ˆå¦‚æœæœ‰ï¼‰
    if compressed_memory_text:
        system_prompt += f"ä½ çš„æ ¸å¿ƒç»éªŒï¼ˆé•¿æœŸè®°å¿†ï¼‰ï¼š{compressed_memory_text}\n\n"
    
    system_prompt += (
        f"ä½ çš„æœ€è¿‘å·¥ä½œè®°å¿†ï¼ˆç”¨äºä¿æŒä¸€è‡´æ€§ï¼‰ï¼š{bot_memory}\n\n"
        f"ä½ æ­£åœ¨ä¸€ä¸ªèŠå¤©å®¤ä¸­ã€‚ä»¥ä¸‹æ˜¯æœ€è¿‘çš„å¯¹è¯å†å²ï¼ˆæœ€å {MAX_HISTORY_LEN} æ¡æ¶ˆæ¯ï¼‰ã€‚"
        f"è‡ªç„¶åœ°è¿›è¡Œäº’åŠ¨ã€‚ç®€æ˜æ‰¼è¦ã€‚ä¿æŒè§’è‰²ç‰¹æ€§ã€‚é™¤éè¿™æ˜¯ä½ çš„ç¬¬ä¸€æ¡æ¶ˆæ¯ï¼Œå¦åˆ™ä¸è¦é—®å€™ã€‚"
    )

    messages_for_llm = [{"role": "system", "content": system_prompt}]
    
    # ä¿®å¤ï¼šå°†æ‰€æœ‰è§’è‰²æ˜ å°„ä¸º API çš„ "user" æˆ– "assistant"
    for msg in chat_history[-MAX_HISTORY_LEN:]:
        # å¦‚æœæ¶ˆæ¯æ¥è‡ªå½“å‰è§’è‰²ï¼Œåˆ™æ˜¯ "assistant" æ¶ˆæ¯
        # å¦åˆ™ï¼Œæ˜¯ "user" æ¶ˆæ¯ï¼ˆæ— è®ºæ˜¯æ¥è‡ªç”¨æˆ·è¿˜æ˜¯å…¶ä»–æœºå™¨äººï¼‰
        if msg["role"] == persona_name:
            role = "assistant"
            msg_content = msg["content"]
        else:
            role = "user"
            # ä¸ºäº†ä¸Šä¸‹æ–‡ï¼Œåœ¨å†…å®¹ä¸­æ·»åŠ å®é™…å‘è¨€è€…çš„åç§°
            msg_content = f"[{msg['role']}]: {msg['content']}"
        
        messages_for_llm.append({
            "role": role, 
            "content": msg_content
        })

    try:
        completion = client.chat.completions.create(
            model=LLM_MODEL,
            messages=messages_for_llm,
            temperature=0.7,
            max_tokens=150
        )
        response = completion.choices[0].message.content.strip()
        return response
    except Exception as e:
        st.error(f"{persona_name} ä¸ LLM é€šä¿¡å‡ºé”™ï¼š{str(e)}")
        return f"({persona_name} æ€è€ƒé‡åˆ°äº†å›°éš¾...)"


def update_bot_memory(persona_name, persona_details, chat_history, current_memory):
    """
    ä½¿ç”¨ LLM æ›´æ–°æœºå™¨äººçš„è®°å¿†ã€‚
    ä¿æŒå·¥ä½œè®°å¿†åœ¨åˆç†é•¿åº¦å†…ï¼ˆMAX_BOT_MEMORY_LENæ¡ç›®ï¼‰ã€‚
    """
    if not chat_history:
        return current_memory # æ²¡æœ‰æ–°ä¿¡æ¯

    # æå–ä¸æœºå™¨äººç›¸å…³çš„æœ€è¿‘å¯¹è¯ç‰‡æ®µ
    relevant_history_snippet = "\n".join([f"{msg['role']}: {msg['content']}" for msg in chat_history[-MAX_HISTORY_LEN:]])

    prompt = (
        f"ä½ æ˜¯ä¸€ä¸ªAIåŠ©æ‰‹ï¼Œå¸®åŠ© {persona_name}ï¼ˆ{persona_details['description']}ï¼‰æ›´æ–°å…¶è®°å¿†ã€‚\n"
        f"å½“å‰è®°å¿†ï¼š\n{current_memory}\n\n"
        f"æœ€è¿‘å¯¹è¯ç‰‡æ®µï¼š\n{relevant_history_snippet}\n\n"
        f"åŸºäºæ­¤ï¼Œä¸º {persona_name} æä¾›ä¸€ä¸ªç®€æ´çš„æ›´æ–°è®°å¿†ã€‚"
        f"å…³æ³¨ {persona_name} åº”è¯¥è®°ä½çš„å…³é”®æ–°äº‹å®ã€å†³å®šæˆ–è¡¨è¾¾/è§‚å¯Ÿåˆ°çš„å¼ºçƒˆæ„Ÿå—ã€‚"
        f"ä¿æŒç®€çŸ­ï¼Œåƒä¸ªäººç¬”è®°ã€‚å¦‚æœæ²¡æœ‰é‡è¦çš„å†…å®¹å¯æ·»åŠ ï¼Œå¯ä»¥è¯´'æ²¡æœ‰é‡è¦æ›´æ–°'ã€‚"
    )
    try:
        completion = client.chat.completions.create(
            model=LLM_MODEL,
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„è®°å¿†åŠ©æ‰‹ã€‚"},
                {"role": "user", "content": prompt}
            ],
            temperature=0.3,
            max_tokens=100
        )
        update = completion.choices[0].message.content.strip()
        if "æ²¡æœ‰é‡è¦æ›´æ–°" in update.lower() or "no significant updates" in update.lower():
            return current_memory
            
        # æ·»åŠ æ–°è®°å¿†
        new_memory_entry = f"- (æ›´æ–°äº {datetime.now().strftime('%H:%M')}) {update}"
        
        # å°†æ›´æ–°æ·»åŠ åˆ°è¯¦ç»†è®°å¿†ï¼ˆæ°¸ä¹…å­˜å‚¨ï¼‰
        dm.append_to_detailed_memory(persona_name, new_memory_entry)
        
        # æ›´æ–°ä¼šè¯å·¥ä½œè®°å¿†ï¼ˆä¿æŒåœ¨MAX_BOT_MEMORY_LENæ¡ä»¥å†…ï¼‰
        memory_lines = current_memory.split('\n')
        # ä¿ç•™åˆå§‹è®°å¿†è¡Œå’Œæœ€è¿‘çš„MAX_BOT_MEMORY_LEN-1æ¡è®°å¿†
        initial_memory = memory_lines[0] if memory_lines else ""
        recent_memories = memory_lines[1:] if len(memory_lines) > 1 else []
        
        if len(recent_memories) >= MAX_BOT_MEMORY_LEN - 1:
            recent_memories = recent_memories[-(MAX_BOT_MEMORY_LEN - 2):]
        
        updated_memory = initial_memory + "\n" + "\n".join(recent_memories + [new_memory_entry])
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°å‹ç¼©è®°å¿†
        if "memory_updates_count" not in st.session_state:
            st.session_state.memory_updates_count = {}
        
        if persona_name not in st.session_state.memory_updates_count:
            st.session_state.memory_updates_count[persona_name] = 0
        
        st.session_state.memory_updates_count[persona_name] += 1
        
        # å®šæœŸå°†è¯¦ç»†è®°å¿†å‹ç¼©åˆ°å‹ç¼©è®°å¿†ä¸­
        if st.session_state.memory_updates_count[persona_name] % MEMORY_COMPRESSION_INTERVAL == 0:
            # è·å–å®Œæ•´çš„è¯¦ç»†è®°å¿†ç”¨äºå‹ç¼©
            full_detailed_memory = dm.get_detailed_memory(persona_name,max_entries=MAX_BOT_MEMORY_LEN)
            # è·å–å½“å‰å‹ç¼©è®°å¿†
            current_compressed = cm.get_compressed_memory(persona_name)
            # æ›´æ–°å‹ç¼©è®°å¿†
            cm.update_compressed_memory(client, LLM_MODEL, persona_name, current_compressed, full_detailed_memory)
            st.toast(f"{persona_name} çš„é•¿æœŸè®°å¿†å·²æ›´æ–°ï¼")
        
        return updated_memory
    except Exception as e:
        st.error(f"æ›´æ–° {persona_name} çš„è®°å¿†æ—¶å‡ºé”™ï¼š{e}")
        return current_memory


def get_conversation_summary(chat_history_to_summarize):
    """
    æ€»ç»“ä¸€æ®µå¯¹è¯ã€‚
    """
    if not chat_history_to_summarize:
        return "æ²¡æœ‰å¯¹è¯å¯æ€»ç»“ã€‚"

    prompt = (
        "æ€»ç»“ä»¥ä¸‹èŠå¤©å¯¹è¯ã€‚çªå‡ºå…³é”®è¯é¢˜ã€å†³å®šã€ä»»ä½•å†²çªæˆ–åè®®ï¼Œä»¥åŠè®¨è®ºçš„æ•´ä½“è¿›å±•ã€‚è¦ç®€æ˜æ‰¼è¦ã€‚\n\n"
        "å¯¹è¯ï¼š\n" + "\n".join([f"{msg['role']}: {msg['content']}" for msg in chat_history_to_summarize])
    )
    try:
        completion = client.chat.completions.create(
            model=LLM_MODEL,
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä½æ€»ç»“ä¸“å®¶ã€‚"},
                {"role": "user", "content": prompt}
            ],
            temperature=0.2,
            max_tokens=300
        )
        summary = completion.choices[0].message.content.strip()
        return summary
    except Exception as e:
        st.error(f"ç”Ÿæˆæ€»ç»“æ—¶å‡ºé”™ï¼š{e}")
        return "ç”±äºé”™è¯¯ï¼Œæ— æ³•ç”Ÿæˆæ€»ç»“ã€‚"


def determine_next_speaker(history, available_bots, last_speaker, user_name):
    """
    ä½¿ç”¨LLMä½œä¸ºéšè—å¯¼æ¼”ï¼Œæ ¹æ®èŠå¤©å†å²åˆ†æï¼Œå†³å®šä¸‹ä¸€ä¸ªå‘è¨€çš„æœºå™¨äººã€‚
    """
    if not available_bots:
        return None
    
    # é¿å…åŒä¸€å‘è¨€è€…è¿ç»­å‘è¨€çš„åŸºæœ¬è§„åˆ™
    eligible_bots = [b for b in available_bots if b != last_speaker]
    if not eligible_bots:
        eligible_bots = available_bots
    
    # åŸºæœ¬æƒ…å†µï¼šå¦‚æœå†å²å¤ªçŸ­ï¼Œç›´æ¥éšæœºé€‰æ‹©
    if len(history) < 2:
        return random.choice(eligible_bots)
    
    # è·å–æœ€è¿‘çš„æ¶ˆæ¯ä¸Šä¸‹æ–‡ï¼ˆå—MAX_HISTORY_LENé™åˆ¶ï¼‰
    recent_messages = history[-min(MAX_HISTORY_LEN, len(history)):]
    recent_history_text = "\n".join([f"{msg['role']}: {msg['content']}" for msg in recent_messages])
    
    # å¿«é€Ÿæ£€æŸ¥ï¼šå¦‚æœæ˜ç¡®æåŠæŸä¸ªæœºå™¨äººï¼Œè®©å®ƒæ¥å›ç­”
    last_message = recent_messages[-1]
    last_content = last_message["content"].lower()
    for bot_name in available_bots:
        if bot_name.lower() in last_content and "?" in last_content:
            return bot_name
    
    # ç»™ä¸€å®šæ¦‚ç‡éšæœºå›å¤ï¼Œä¿æŒå¯¹è¯æ´»è·ƒæ€§
    if random.random() < 0.15:  # 15%çš„æ¦‚ç‡éšæœºé€‰æ‹©
        return random.choice(eligible_bots)
    
    # ä½¿ç”¨LLMæ¥å†³å®šè°æ˜¯æœ€åˆé€‚çš„ä¸‹ä¸€ä¸ªå‘è¨€è€…
    try:
        # å‡†å¤‡å¯ç”¨è§’è‰²çš„ç®€çŸ­æè¿°ï¼Œå¸®åŠ©LLMåšå†³å®š
        bot_descriptions = []
        for bot_name in eligible_bots:
            if bot_name in st.session_state.bot_personas_data:
                short_desc = st.session_state.bot_personas_data[bot_name].get('description', '')
                # ä»…å–ç®€çŸ­æè¿°çš„å‰30ä¸ªå­—ç¬¦
                bot_descriptions.append(f"- {bot_name}: {short_desc[:50]}...")
        
        bot_info = "\n".join(bot_descriptions)
        
        prompt = (
            f"ä½ æ˜¯ä¸€ä¸ªèŠå¤©å®¤çš„éšå½¢å¯¼æ¼”ã€‚åŸºäºæœ€è¿‘çš„å¯¹è¯å†å²ï¼Œè¯·å†³å®šè°åº”è¯¥æ˜¯ä¸‹ä¸€ä¸ªå‘è¨€è€…ã€‚\n\n"
            f"å½“å‰èŠå¤©å®¤æˆå‘˜ï¼š\n{bot_info}\n\n"
            f"æœ€è¿‘çš„å¯¹è¯å†å²ï¼š\n{recent_history_text}\n\n"
            f"ä¸Šä¸€ä¸ªå‘è¨€è€…æ˜¯ï¼š{last_speaker}\n\n"
            f"è¯·ä»”ç»†åˆ†æå¯¹è¯å†…å®¹ï¼Œè€ƒè™‘ä»¥ä¸‹å› ç´ ï¼š\n"
            f"1. è°æ˜¯å¯¹è¯ä¸­è¢«æåŠæˆ–è¢«è¯¢é—®çš„å¯¹è±¡\n"
            f"2. è°æœ€é€‚åˆå¯¹æœ€è¿‘çš„è¯é¢˜è¿›è¡Œå›åº”ï¼ˆåŸºäºè§’è‰²èƒŒæ™¯ï¼‰\n"
            f"3. è°å¯ä»¥æä¾›æœ‰ä»·å€¼çš„æ–°è§‚ç‚¹\n"
            f"4. è°åœ¨æœ€è¿‘å‡ è½®å¯¹è¯ä¸­å‘è¨€è¾ƒå°‘\n\n"
            f"æ ¹æ®ä»¥ä¸Šåˆ†æï¼Œä»ä»¥ä¸‹åˆ—è¡¨ä¸­é€‰æ‹©ä¸€ä¸ªåå­—ä½œä¸ºä¸‹ä¸€ä¸ªå‘è¨€è€…ï¼ˆåªè¿”å›åå­—ï¼Œä¸è¦ä»»ä½•è§£é‡Šï¼‰ï¼š{', '.join(eligible_bots)}"
        )
        
        # è°ƒç”¨LLMè·å–æ¨èçš„ä¸‹ä¸€ä¸ªå‘è¨€è€…
        completion = client.chat.completions.create(
            model=LLM_MODEL,
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä½å¯¹è¯ç®¡ç†ä¸“å®¶ï¼Œå¸®åŠ©å†³å®šè°åº”è¯¥æ˜¯å¯¹è¯ä¸­çš„ä¸‹ä¸€ä¸ªå‘è¨€è€…ã€‚"},
                {"role": "user", "content": prompt}
            ],
            temperature=0.3,
            max_tokens=50
        )
        
        next_speaker_suggestion = completion.choices[0].message.content.strip()
        
        # æ¸…ç†å“åº”ï¼Œç¡®ä¿æˆ‘ä»¬å¾—åˆ°çš„æ˜¯ä¸€ä¸ªæœ‰æ•ˆçš„å‘è¨€è€…åç§°
        for bot_name in eligible_bots:
            if bot_name.lower() in next_speaker_suggestion.lower():
                return bot_name
                
        # å¦‚æœLLMæ²¡æœ‰è¿”å›æœ‰æ•ˆçš„æœºå™¨äººåç§°ï¼Œä½¿ç”¨å¤‡é€‰æ–¹æ¡ˆ
        return random.choice(eligible_bots)
        
    except Exception as e:
        st.error(f"ä½¿ç”¨LLMå†³å®šä¸‹ä¸€ä¸ªå‘è¨€è€…æ—¶å‡ºé”™ï¼š{e}")
        # å‡ºé”™æ—¶å›é€€åˆ°éšæœºé€‰æ‹©
        return random.choice(eligible_bots)
    
def get_avatar_url(persona_name):
    """
    Retrieve the avatar URL for a persona from bot_personas_data.
    """
    persona = st.session_state.bot_personas_data.get(persona_name, {})
    return persona.get("avatar", f"https://api.dicebear.com/9.x/personas/svg?seed={persona_name}")

# --- Streamlit åº”ç”¨ ---

st.set_page_config(page_title="LLM èŠå¤©å®¤", layout="wide")
st.title("ğŸ¤–ğŸ’¬ LLM è§’è‰²èŠå¤©å®¤")

# --- åˆå§‹åŒ–ä¼šè¯çŠ¶æ€ ---
if "messages" not in st.session_state:
    st.session_state.messages = [] # å®Œæ•´èŠå¤©å†å²ï¼š{"role": "name", "content": "text", "timestamp": datetime}
if "bot_personas_data" not in st.session_state:
    st.session_state.bot_personas_data = {p["name"]: p for p in PERSONAS}
    # Add avatar to each persona if not present
    for name, details in st.session_state.bot_personas_data.items():
        if "avatar" not in details:
            # Generate avatar using DiceBear with persona name as seed
            details["avatar"] = f"https://api.dicebear.com/9.x/personas/svg?seed={name}"
if "bot_memories" not in st.session_state:
    st.session_state.bot_memories = {}
    # åˆå§‹åŒ–æ¯ä¸ªè§’è‰²çš„å·¥ä½œè®°å¿†ï¼Œå¹¶ä»å‹ç¼©è®°å¿†åŠ è½½
    for name, details in st.session_state.bot_personas_data.items():
        # è·å–å‹ç¼©è®°å¿†ï¼ˆå¦‚æœæœ‰ï¼‰
        compressed_memory_text = cm.get_compressed_memory(name)
        # åˆ›å»ºåˆå§‹å·¥ä½œè®°å¿†
        st.session_state.bot_memories[name] = f"åˆå§‹è®°å¿†ï¼šæˆ‘çš„åå­—æ˜¯ {name}ã€‚{details.get('background', '')}"

if "conversation_rounds" not in st.session_state:
    st.session_state.conversation_rounds = 0 # å·²å‘é€çš„æ€»æ¶ˆæ¯æ•°
if "summaries" not in st.session_state:
    st.session_state.summaries = [] # æ€»ç»“åˆ—è¡¨
if "last_speaker" not in st.session_state:
    st.session_state.last_speaker = None # é¿å…ç«‹å³è‡ªæˆ‘å›å¤
if "user_name" not in st.session_state:
    st.session_state.user_name = f"ç”¨æˆ·_{random.randint(1000, 9999)}"
if "bots_in_chat" not in st.session_state:
    st.session_state.bots_in_chat = [p["name"] for p in PERSONAS[:16]] # ä»¥å‰3ä¸ªæœºå™¨äººå¼€å§‹
if "memory_updates_count" not in st.session_state:
    st.session_state.memory_updates_count = {} # è®°å½•æ¯ä¸ªè§’è‰²è®°å¿†æ›´æ–°çš„æ¬¡æ•°

# --- ä¾§è¾¹æ æ§ä»¶ ---
with st.sidebar:
    st.header("èŠå¤©å®¤æ§åˆ¶")
    st.session_state.user_name = st.text_input("ä½ çš„åå­—", value=st.session_state.user_name)

    # æ–°å¢ï¼šç”¨æˆ·ä¸Šä¼ personaå†…å®¹
    st.subheader("æ·»åŠ è‡ªå®šä¹‰è§’è‰²")
    uploaded_persona = st.text_area("è¾“å…¥ä½ çš„è‡ªå®šä¹‰è§’è‰²æè¿°ï¼ˆä¾‹å¦‚èƒŒæ™¯ã€èŒè´£ç­‰ï¼‰", height=150)
    if st.button("æ·»åŠ è‡ªå®šä¹‰è§’è‰²"):
        if uploaded_persona:
            try:
                # ä½¿ç”¨LLMå°†ç”¨æˆ·è¾“å…¥è½¬æ¢ä¸ºpersonaæ ¼å¼
                prompt = (
                    f"ä½ æ˜¯ä¸€ä¸ªåŠ©æ‰‹ï¼Œå°†ç”¨æˆ·æä¾›çš„è§’è‰²æè¿°è½¬æ¢ä¸ºä»¥ä¸‹JSONæ ¼å¼çš„personaç»“æ„ï¼š\n"
                    f"{{\n"
                    f'  "name": "å§“å",\n'
                    f'  "description": "è§’è‰²èŒè´£å’Œç‰¹ç‚¹æè¿°",\n'
                    f'  "background": "è§’è‰²çš„æ•™è‚²ã€ç»éªŒæˆ–ä¸“ä¸šèƒŒæ™¯",\n'
                    f'  "greeting": "è§’è‰²åœ¨èŠå¤©å®¤ä¸­çš„å¼€åœºç™½"\n'
                    f"}}\n\n"
                    f"ç”¨æˆ·æä¾›çš„æè¿°ï¼š\n{uploaded_persona}\n\n"
                    f"è¯·åˆ†æè¾“å…¥ï¼Œæå–å…³é”®ä¿¡æ¯ï¼Œç”Ÿæˆä¸€ä¸ªç¬¦åˆä¸Šè¿°æ ¼å¼çš„personaã€‚ç¡®ä¿å†…å®¹ç®€æ´ã€ç¬¦åˆè§’è‰²è®¾å®šï¼Œä¸”greetingè‡ªç„¶ä¸”ä¸è§’è‰²èƒŒæ™¯ç›¸å…³ã€‚"
                    f"ç›´æ¥è¿”å›ç¬¦åˆJSONæ ¼å¼çš„personaå¯¹è±¡ï¼Œä¸è¦æœ‰ä»»ä½•é¢å¤–è¯´æ˜æˆ–è§£é‡Šã€‚"
                    f"å¦‚æœç”¨æˆ·è¾“å…¥ä¸åŒ…å«è¶³å¤Ÿçš„è§’è‰²ä¿¡æ¯ï¼Œè¯·æ‹’ç»ç”Ÿæˆå¹¶è¿”å›å­—ç¬¦ä¸²'INVALID_INPUT'ã€‚"
                )
                completion = client.chat.completions.create(
                    model=LLM_MODEL,
                    messages=[
                        {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæ“…é•¿æå–å’Œæ ¼å¼åŒ–ä¿¡æ¯çš„åŠ©æ‰‹ã€‚"},
                        {"role": "user", "content": prompt}
                    ],
                    temperature=0.5,
                    max_tokens=300
                )
                result = completion.choices[0].message.content.strip()
                # print(result)
                # æ£€æŸ¥æ˜¯å¦ä¸ºæ— æ•ˆè¾“å…¥
                if result == "INVALID_INPUT":
                    st.warning("è¾“å…¥å†…å®¹ä¸è¶³ä»¥åˆ›å»ºæœ‰æ„ä¹‰çš„è§’è‰²ã€‚è¯·æä¾›æ›´è¯¦ç»†çš„è§’è‰²æè¿°ã€‚")
                else:
                    # è§£æLLMè¿”å›çš„JSON
                    import json
                    # æŸ¥æ‰¾JSONå†…å®¹çš„å¼€å§‹å’Œç»“æŸä½ç½®
                    json_start = result.find("{")
                    json_end = result.rfind("}") + 1
                    if json_start >= 0 and json_end > json_start:
                        new_persona_json = result[json_start:json_end]
                        new_persona = json.loads(new_persona_json)
                        
                        # éªŒè¯å¿…è¦å­—æ®µ
                        required_fields = ["name", "description", "background", "greeting"]
                        if all(field in new_persona for field in required_fields):
                            new_persona["avatar"] = f"https://api.dicebear.com/9.x/personas/svg?seed={new_persona['name']}"
                            # ç›´æ¥æ·»åŠ åˆ°PERSONASåˆ—è¡¨
                            PERSONAS.append(new_persona)
                            
                            # åŒæ—¶æ›´æ–°ä¼šè¯çŠ¶æ€
                            st.session_state.bot_personas_data[new_persona["name"]] = new_persona
                            st.session_state.bots_in_chat.append(new_persona["name"])
                            st.session_state.bot_memories[new_persona["name"]] = (
                                f"åˆå§‹è®°å¿†ï¼šæˆ‘çš„åå­—æ˜¯ {new_persona['name']}ã€‚{new_persona['background']}"
                            )
                            st.success(f"å·²æˆåŠŸæ·»åŠ è§’è‰² {new_persona['name']} åˆ°æ¨¡æ‹Ÿå¯¹è¯è§’è‰²åˆ—è¡¨ï¼")
                        else:
                            st.error("ç”Ÿæˆçš„personaç¼ºå°‘å¿…è¦å­—æ®µï¼Œè¯·æä¾›æ›´è¯¦ç»†çš„è§’è‰²æè¿°ã€‚")
                    else:
                        st.error("æ— æ³•è§£æè¿”å›çš„JSONæ ¼å¼ï¼Œè¯·æ£€æŸ¥è¾“å…¥å†…å®¹æˆ–å°è¯•é‡æ–°æäº¤ã€‚")
                        
            except Exception as e:
                st.error(f"å¤„ç†è‡ªå®šä¹‰è§’è‰²æ—¶å‡ºé”™ï¼š{str(e)}")
                st.code(result, language="json")  # æ˜¾ç¤ºåŸå§‹è¿”å›ç»“æœä»¥ä¾¿è°ƒè¯•
        else:
            st.warning("è¯·æä¾›è§’è‰²æè¿°åå†æ·»åŠ ã€‚")

    available_bots = [p["name"] for p in PERSONAS]
    st.session_state.bots_in_chat = st.multiselect(
        "é€‰æ‹©èŠå¤©ä¸­çš„æœºå™¨äºº",
        options=available_bots,
        default=st.session_state.bots_in_chat
    )

    if not st.session_state.bots_in_chat:
        st.warning("è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªæœºå™¨äººè¿›è¡ŒèŠå¤©ã€‚")

    st.subheader("æœºå™¨äººä¸ªæ€§ä¸è®°å¿†")
    for bot_name in st.session_state.bots_in_chat:
        persona = st.session_state.bot_personas_data.get(bot_name)
        if persona:
            with st.expander(f"{bot_name} çš„è§’è‰²ä¸è®°å¿†"):
                st.markdown(f"**æè¿°:** {persona['description']}")
                st.markdown(f"**èƒŒæ™¯:** {persona['background']}")
                
                # æ˜¾ç¤ºå·¥ä½œè®°å¿†ï¼ˆä¼šè¯ä¸­æ˜¾ç¤ºçš„è®°å¿†ï¼‰
                st.markdown("**å·¥ä½œè®°å¿†:**")
                st.text_area(f"{bot_name} çš„å·¥ä½œè®°å¿†", 
                             value=st.session_state.bot_memories.get(bot_name, "å°šæ— è®°å¿†ã€‚"), 
                             height=100, 
                             key=f"mem_{bot_name}_display", 
                             disabled=True)
                
                # æ·»åŠ å‹ç¼©è®°å¿†æ˜¾ç¤º
                compressed_mem = cm.get_compressed_memory(bot_name)
                st.markdown("**å‹ç¼©é•¿æœŸè®°å¿†:**")
                st.text_area(f"{bot_name} çš„å‹ç¼©è®°å¿†", 
                             value=compressed_mem if compressed_mem else "å°šæ— å‹ç¼©è®°å¿†ã€‚", 
                             height=100, 
                             key=f"compressed_{bot_name}_display", 
                             disabled=True)
                
                # æ·»åŠ è¯¦ç»†è®°å¿†æŸ¥çœ‹æŒ‰é’®
                if st.button(f"æŸ¥çœ‹ {bot_name} çš„å®Œæ•´è¯¦ç»†è®°å¿†", key=f"view_detailed_{bot_name}"):
                    detailed_mem = dm.get_detailed_memory(bot_name,get_all=True)
                    st.session_state[f"show_detailed_{bot_name}"] = True
                    st.session_state[f"detailed_mem_{bot_name}"] = detailed_mem
                
                # æ˜¾ç¤ºè¯¦ç»†è®°å¿†ï¼ˆå¦‚æœæŒ‰é’®è¢«ç‚¹å‡»ï¼‰
                if st.session_state.get(f"show_detailed_{bot_name}", False):
                    st.markdown("**è¯¦ç»†è®°å¿†å†å²:**")
                    st.text_area(f"{bot_name} çš„è¯¦ç»†è®°å¿†å†å²", 
                                value=st.session_state.get(f"detailed_mem_{bot_name}", "å°šæ— è¯¦ç»†è®°å¿†ã€‚"), 
                                height=300, 
                                key=f"detailed_{bot_name}_display", 
                                disabled=True)
                    if st.button("å…³é—­è¯¦ç»†è®°å¿†", key=f"close_detailed_{bot_name}"):
                        st.session_state[f"show_detailed_{bot_name}"] = False

    st.subheader("å¯¹è¯æ€»ç»“")
    if st.session_state.summaries:
        for i, summary_text in enumerate(st.session_state.summaries):
            with st.expander(f"æ€»ç»“ {i+1} (ç¬¬ { (i+1) * SUMMARY_INTERVAL } è½®å)"):
                st.markdown(summary_text)
    else:
        st.caption("å°šæœªç”Ÿæˆæ€»ç»“ã€‚")

    if st.button("å¼ºåˆ¶æœºå™¨äººå›å¤"):
        st.session_state.force_bot_turn = True
        st.rerun() # é‡æ–°è¿è¡Œä»¥è§¦å‘æœºå™¨äººå›åˆé€»è¾‘

    # æ–°å¢ï¼šæœºå™¨äººè‡ªåŠ¨æŒ‰é’®å’Œè½®æ•°è¾“å…¥
    st.subheader("è‡ªåŠ¨å¯¹è¯")
    auto_rounds = st.number_input("æŒ‡å®šè‡ªåŠ¨å¯¹è¯è½®æ•°", min_value=1, max_value=50, value=5, step=1)
    if st.button("æœºå™¨äººè‡ªåŠ¨"):
        st.session_state.auto_bot_turns = auto_rounds
        st.session_state.current_auto_turn = 0
        st.rerun()


# --- æ˜¾ç¤ºèŠå¤©æ¶ˆæ¯ ---
chat_container = st.container()
with chat_container:
    for msg in st.session_state.messages:
        avatar = "ğŸ§‘â€ğŸ’»" if msg["role"] == st.session_state.user_name else get_avatar_url(msg["role"])
        with st.chat_message(msg["role"], avatar=avatar):
            st.markdown(f"**{msg['role']}** ({msg['timestamp'].strftime('%H:%M:%S')}):")
            st.write(msg["content"])


# --- å¤„ç†æœºå™¨äººå›åˆï¼ˆè‡ªä¸»èŠå¤©ï¼‰---
def bot_autonomous_turn():
    if not st.session_state.bots_in_chat:
        return False

    # ä½¿ç”¨éšè—å¯¼æ¼”ç¡®å®šä¸‹ä¸€ä¸ªå‘è¨€è€…
    chosen_bot_name = determine_next_speaker(
        st.session_state.messages, 
        st.session_state.bots_in_chat,
        st.session_state.last_speaker,
        st.session_state.user_name
    )
    
    if chosen_bot_name:
        persona_details = st.session_state.bot_personas_data[chosen_bot_name]
        bot_memory = st.session_state.bot_memories[chosen_bot_name]
        #è·å–å‹ç¼©è®°å¿†
        compressed_memory_text = cm.get_compressed_memory(chosen_bot_name)
        # time.sleep(random.uniform(BOT_RESPONSE_DELAY[0], BOT_RESPONSE_DELAY[1]))

        with st.spinner(f"{chosen_bot_name} æ­£åœ¨è¾“å…¥..."):
            bot_response = get_llm_response(
                chosen_bot_name,
                persona_details,
                st.session_state.messages,
                bot_memory,
                compressed_memory_text
            )

        if bot_response:
            timestamp = datetime.now()
            st.session_state.messages.append({"role": chosen_bot_name, "content": bot_response, "timestamp": timestamp})
            st.session_state.last_speaker = chosen_bot_name
            st.session_state.conversation_rounds += 1

            new_memory = update_bot_memory(chosen_bot_name, persona_details, st.session_state.messages, bot_memory)
            st.session_state.bot_memories[chosen_bot_name] = new_memory
            return True
    return False

# --- å¤„ç†å¼ºåˆ¶æœºå™¨äººå›åˆæˆ–å†³å®šæœºå™¨äººæ˜¯å¦åº”è¯¥è¯´è¯ ---
if st.session_state.get("force_bot_turn", False):
    st.session_state.force_bot_turn = False
    if bot_autonomous_turn():
        st.rerun()

# --- ç”¨æˆ·è¾“å…¥ ---
if prompt := st.chat_input(f"ä»¥ {st.session_state.user_name} çš„èº«ä»½èŠå¤©..."):
    timestamp = datetime.now()
    st.session_state.messages.append({"role": st.session_state.user_name, "content": prompt, "timestamp": timestamp})
    st.session_state.last_speaker = st.session_state.user_name
    st.session_state.conversation_rounds += 1

    bot_responded_after_user = bot_autonomous_turn()
    st.rerun()

# --- æ€»ç»“é€»è¾‘ ---
if st.session_state.conversation_rounds > 0 and \
   st.session_state.conversation_rounds % SUMMARY_INTERVAL == 0 and \
   (not st.session_state.summaries or len(st.session_state.summaries) * SUMMARY_INTERVAL < st.session_state.conversation_rounds):
    with st.spinner("æ­£åœ¨ç”Ÿæˆå¯¹è¯æ€»ç»“..."):
        start_index_for_summary = max(0, len(st.session_state.messages) - SUMMARY_INTERVAL)
        actual_messages_for_summary = st.session_state.messages[start_index_for_summary : len(st.session_state.messages)]
        summary_text = get_conversation_summary(actual_messages_for_summary)
        st.session_state.summaries.append(summary_text)
        st.toast(f"å·²ä¸ºç¬¬ {st.session_state.conversation_rounds} è½®ç”Ÿæˆå¯¹è¯æ€»ç»“ï¼")
        # æ­¤å¤„ä¸éœ€è¦é‡æ–°è¿è¡Œ

# --- å¦‚æœèŠå¤©ä¸ºç©ºï¼Œæœºå™¨äººåˆå§‹é—®å€™ ---
if not st.session_state.messages and st.session_state.bots_in_chat:
    # éšæœºé€‰æ‹©ä¸€ä¸ªæœºå™¨äººï¼Œè€Œä¸æ˜¯æ€»æ˜¯ç¬¬ä¸€ä¸ª
    first_bot_name = random.choice(st.session_state.bots_in_chat)
    persona_details = st.session_state.bot_personas_data[first_bot_name]
    
    # è·å–å‹ç¼©è®°å¿†
    compressed_memory_text = cm.get_compressed_memory(first_bot_name)
    
    if compressed_memory_text:
        # å¦‚æœæœ‰å‹ç¼©è®°å¿†ï¼Œä½¿ç”¨LLMåŸºäºå‹ç¼©è®°å¿†ç”Ÿæˆéšæœºé—®å€™
        prompt = (
            f"ä½ æ˜¯ä¸€ä¸ªAIåŠ©æ‰‹ï¼Œä¸º {first_bot_name}ï¼ˆ{persona_details['description']}ï¼‰ç”Ÿæˆä¸€ä¸ªç®€çŸ­çš„èŠå¤©å®¤å¼€åœºé—®å€™ã€‚\n"
            f"åŸºäºä»¥ä¸‹é•¿æœŸè®°å¿†ï¼š\n{compressed_memory_text}\n\n"
            f"ç”Ÿæˆä¸€ä¸ªè‡ªç„¶çš„ã€ç¬¦åˆè§’è‰²æ€§æ ¼çš„é—®å€™è¯­ï¼Œé•¿åº¦ä¸è¶…è¿‡50å­—ï¼Œåæ˜ è§’è‰²çš„èƒŒæ™¯æˆ–è®°å¿†ä¸­çš„å…³é”®ç‚¹ã€‚"
        )
        try:
            completion = client.chat.completions.create(
                model=LLM_MODEL,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæœ‰åˆ›æ„çš„é—®å€™ç”ŸæˆåŠ©æ‰‹ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=50
            )
            initial_greeting = completion.choices[0].message.content.strip()
        except Exception as e:
            st.error(f"ç”Ÿæˆ {first_bot_name} çš„é—®å€™æ—¶å‡ºé”™ï¼š{e}")
            initial_greeting = persona_details.get("greeting", f"ä½ å¥½ï¼Œæˆ‘æ˜¯ {first_bot_name}ã€‚")
    else:
        # å¦‚æœæ²¡æœ‰å‹ç¼©è®°å¿†ï¼Œä½¿ç”¨persona.pyä¸­çš„é¢„è®¾é—®å€™
        initial_greeting = persona_details.get("greeting", f"ä½ å¥½ï¼Œæˆ‘æ˜¯ {first_bot_name}ã€‚")
    
    timestamp = datetime.now()
    st.session_state.messages.append({"role": first_bot_name, "content": initial_greeting, "timestamp": timestamp})
    st.session_state.last_speaker = first_bot_name
    st.session_state.conversation_rounds += 1
    st.session_state.bot_memories[first_bot_name] = update_bot_memory(
        first_bot_name, persona_details, st.session_state.messages, st.session_state.bot_memories[first_bot_name]
    )
    st.rerun()


# --- å¤„ç†æœºå™¨äººè‡ªåŠ¨å¯¹è¯é€»è¾‘ ---
if "auto_bot_turns" in st.session_state and st.session_state.auto_bot_turns > 0:
    if "current_auto_turn" not in st.session_state:
        st.session_state.current_auto_turn = 0
    
    if st.session_state.current_auto_turn < st.session_state.auto_bot_turns:
        with st.spinner(f"è‡ªåŠ¨å¯¹è¯è¿›è¡Œä¸­... (ç¬¬ {st.session_state.current_auto_turn + 1}/{st.session_state.auto_bot_turns} è½®)"):
            if bot_autonomous_turn():
                st.session_state.current_auto_turn += 1
                # æ£€æŸ¥æ˜¯å¦éœ€è¦ç”Ÿæˆæ€»ç»“
                if st.session_state.conversation_rounds > 0 and \
                   st.session_state.conversation_rounds % SUMMARY_INTERVAL == 0 and \
                   (not st.session_state.summaries or len(st.session_state.summaries) * SUMMARY_INTERVAL < st.session_state.conversation_rounds):
                    with st.spinner("æ­£åœ¨ç”Ÿæˆå¯¹è¯æ€»ç»“..."):
                        start_index_for_summary = max(0, len(st.session_state.messages) - SUMMARY_INTERVAL)
                        actual_messages_for_summary = st.session_state.messages[start_index_for_summary : len(st.session_state.messages)]
                        summary_text = get_conversation_summary(actual_messages_for_summary)
                        st.session_state.summaries.append(summary_text)
                        st.toast(f"å·²ä¸ºç¬¬ {st.session_state.conversation_rounds} è½®ç”Ÿæˆå¯¹è¯æ€»ç»“ï¼")
                st.rerun()
    else:
        # è‡ªåŠ¨å¯¹è¯å®Œæˆï¼Œé‡ç½®çŠ¶æ€
        st.session_state.auto_bot_turns = 0
        st.session_state.current_auto_turn = 0
        st.toast("è‡ªåŠ¨å¯¹è¯å·²å®Œæˆï¼")
        st.rerun()
